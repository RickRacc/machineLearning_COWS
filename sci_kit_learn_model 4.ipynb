{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9c0ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87ea42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cattle_data_train.csv\")\n",
    "\n",
    "features = data.iloc[:, 1:-1]\n",
    "yields = data.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c03tkdlkdj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (210000, 36)\n",
      "Cleaned shape: (210000, 15)\n",
      "Removed 21 features\n"
     ]
    }
   ],
   "source": [
    "# Feature Removal and Preprocessing\n",
    "# Based on correlation analysis and data quality issues\n",
    "\n",
    "# Features to remove:\n",
    "features_to_remove = [\n",
    "    'Feed_Quantity_lb',      # Duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "    'Cattle_ID',             # Unique identifier, no predictive value\n",
    "    'Rumination_Time_hrs',   # 55% negative values - data quality issue\n",
    "    'HS_Vaccine',            # Very low correlation (0.000034)\n",
    "    'BQ_Vaccine',            # Very low correlation (0.000466)\n",
    "    'BVD_Vaccine',           # Very low correlation (0.000491)\n",
    "    'Brucellosis_Vaccine',   # Very low correlation (0.002089)\n",
    "    'FMD_Vaccine',           # Very low correlation (0.002477)\n",
    "    'Anthrax_Vaccine', \n",
    "    'IBR_Vaccine', \n",
    "    'Rabies_Vaccine',\n",
    "    'Walking_Distance_km',\n",
    "    'Climate_Zone',\n",
    "    'Farm_ID',\n",
    "    'Resting_Hours',         # Nearly zero correlation (0.001653)\n",
    "    'Housing_Score',         # Low correlation (0.004) + 3% missing values\n",
    "    'Feeding_Frequency',     # No correlation (0.000380)\n",
    "    'Body_Condition_Score',  # No correlation (0.001647)\n",
    "    'Humidity_percent',      # Very low correlation (0.002153)\n",
    "    'Grazing_Duration_hrs',  # Very low correlation (0.004350)\n",
    "    'Milking_Interval_hrs'   # Very low correlation (0.014734)\n",
    "]\n",
    "\n",
    "# Remove features\n",
    "data_cleaned = data.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"Cleaned shape: {data_cleaned.shape}\")\n",
    "print(f\"Removed {len(features_to_remove)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "qb4zf4aahh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced Date with Season:\n",
      "  - Season (Winter/Spring/Summer/Fall)\n",
      "\n",
      "Season distribution:\n",
      "Season\n",
      "Fall      52425\n",
      "Spring    53061\n",
      "Summer    52663\n",
      "Winter    51851\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final shape: (210000, 15)\n"
     ]
    }
   ],
   "source": [
    "# Extract Season from Date column\n",
    "# Analysis shows seasons have strong effect on milk yield:\n",
    "#   - Spring: 16.59 L (+6.4% vs average) - BEST season\n",
    "#   - Winter: 16.12 L (+3.4% vs average)\n",
    "#   - Fall:   15.70 L (+0.7% vs average)\n",
    "#   - Summer: 13.94 L (-10.6% vs average) - WORST season (heat stress)\n",
    "#   - Range: 2.65 L difference between best and worst seasons!\n",
    "\n",
    "# Convert Date to datetime\n",
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "\n",
    "# Extract month temporarily to create seasons\n",
    "data_cleaned['Month'] = data_cleaned['Date'].dt.month\n",
    "\n",
    "# Create Season feature (meteorological seasons)\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Fall'\n",
    "\n",
    "data_cleaned['Season'] = data_cleaned['Month'].apply(get_season)\n",
    "\n",
    "# Drop both Date and Month (we only keep Season)\n",
    "data_cleaned = data_cleaned.drop(columns=['Date', 'Month'])\n",
    "\n",
    "print(\"Replaced Date with Season:\")\n",
    "print(\"  - Season (Winter/Spring/Summer/Fall)\")\n",
    "print(f\"\\nSeason distribution:\")\n",
    "print(data_cleaned['Season'].value_counts().sort_index())\n",
    "print(f\"\\nFinal shape: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced80a13fbi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (210000, 14)\n",
      "Target shape: (210000,)\n"
     ]
    }
   ],
   "source": [
    "# Update features and target using cleaned data\n",
    "features = data_cleaned.drop(columns=['Milk_Yield_L'])\n",
    "yields = data_cleaned['Milk_Yield_L']\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target shape: {yields.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rxi9fuc5r6j",
   "metadata": {},
   "source": [
    "## Summary of Feature Selection\n",
    "\n",
    "**Removed 16 features:**\n",
    "1. Feed_Quantity_lb - duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "2. Cattle_ID - unique identifier, no predictive value\n",
    "3. Rumination_Time_hrs - data quality issue (55% negative values)\n",
    "4-8. Low-correlation vaccines: HS, BQ, BVD, Brucellosis, FMD\n",
    "9-15. Zero/near-zero correlation: Resting_Hours, Housing_Score, Feeding_Frequency, Walking_Distance_km, Body_Condition_Score, Humidity_percent, Grazing_Duration_hrs\n",
    "16. Milking_Interval_hrs - very low correlation (0.015)\n",
    "\n",
    "**Replaced Date with Season:**\n",
    "- Removed: Date (raw timestamp)\n",
    "- Added: Season (Winter/Spring/Summer/Fall)\n",
    "- Rationale: Strong seasonal effect on milk yield (Spring: 16.59L vs Summer: 13.94L = 2.65L range)\n",
    "- Month was NOT kept (redundant with Season - only 0.1L variation within seasons)\n",
    "\n",
    "**Final: 19 features (down from 35 = 46% reduction)**\n",
    "\n",
    "**Categorical (7):**\n",
    "- Breed, Climate_Zone, Management_System, Lactation_Stage, Feed_Type, Farm_ID, Season\n",
    "\n",
    "**Numeric (12):**\n",
    "- Age_Months (corr: 0.31), Weight_kg (0.30), Parity (0.24), Days_in_Milk (0.06), Feed_Quantity_kg (0.22), Water_Intake_L (0.12), Ambient_Temperature_C (0.04), Anthrax_Vaccine (0.07), IBR_Vaccine (0.07), Rabies_Vaccine (0.07), Previous_Week_Avg_Yield (0.09), Mastitis (0.12)\n",
    "\n",
    "**Why this works:**\n",
    "- Removed noisy, low-correlation features\n",
    "- Kept strong predictors (Age, Weight, Parity, Feed)\n",
    "- Captured seasonal patterns without overfitting to specific months\n",
    "- Cleaner data (fixed Rumination_Time_hrs corruption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a304fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Breed', 'Management_System', 'Lactation_Stage', 'Feed_Type', 'Season']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Update categorical columns from cleaned data\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "print(f\"Categorical columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4738e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, mode=\"freq\", m=5):\n",
    "        self.cols = cols\n",
    "        self.mode = mode\n",
    "        self.m = m\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.maps = {}\n",
    "\n",
    "        for col in self.cols:\n",
    "            freq = X[col].value_counts()\n",
    "            total = len(X)\n",
    "\n",
    "            if self.mode == \"freq\":\n",
    "                enc = freq / total\n",
    "            elif self.mode == \"count\":\n",
    "                enc = freq\n",
    "            elif self.mode == \"logfreq\":\n",
    "                enc = np.log1p(freq / total)\n",
    "            elif self.mode == \"smooth\":\n",
    "                prior = freq.sum() / total\n",
    "                enc = (freq + self.m * prior) / (freq.sum() + self.m)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown mode: \" + self.mode)\n",
    "\n",
    "            self.maps[col] = enc\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].map(self.maps[col]).fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f539e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008065429868602329, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.007419939418114052, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.177700028552196, 4.169963405525027, 4.185445143124457, 4.188170677618678, 4.185743733732288]\n",
      "Mean RMSE: 4.18140459771053\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.00016601864044243653, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0010997491581800289, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.218094927160684, 4.1818754574130255, 4.220593040863834, 4.198232433908467, 4.190264030489418]\n",
      "Mean RMSE: 4.201811977967085\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.00034370861113902185, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0003058449429580245, 'pca__n_components': 30}\n",
      "RMSE for each fold: [4.172125759273878, 4.168604964480251, 4.225173492063706, 4.224660483371436, 4.182963270344595]\n",
      "Mean RMSE: 4.1947055939067734\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0008424426408004218, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00010778765841014329, 'pca__n_components': 30}\n",
      "RMSE for each fold: [4.235880287166988, 4.234579617889855, 4.247153007289673, 4.247025445889965, 4.239669226456325]\n",
      "Mean RMSE: 4.24086151693856\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0006274815096277166, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.005347564316322379, 'pca__n_components': 30}\n",
      "RMSE for each fold: [4.200162805786448, 4.198031261247442, 4.209603087957106, 4.2006614733322465, 4.205329784391529]\n",
      "Mean RMSE: 4.202757682542955\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.00030122914019804195, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.004098609717152555, 'pca__n_components': 30}\n",
      "RMSE for each fold: [4.227613485300512, 4.19141243477891, 4.207416491199241, 4.209914925865063, 4.204610037027022]\n",
      "Mean RMSE: 4.208193474834149\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009837555188414592, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.004660699842170359, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.186327181687981, 4.18119056006748, 4.193819479030074, 4.201019905569505, 4.192351816427384]\n",
      "Mean RMSE: 4.190941788556485\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.00020967378215835974, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.009932308858067881, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.195280263641858, 4.194875794802918, 4.2073473536502, 4.201062571492582, 4.204971467185548]\n",
      "Mean RMSE: 4.200707490154621\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008699404067363205, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0018052412368729153, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.182344186420038, 4.186489318441551, 4.199427003860216, 4.191538185391306, 4.193306703624334]\n",
      "Mean RMSE: 4.190621079547489\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009588855372533333, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00818397348116461, 'pca__n_components': 20}\n",
      "RMSE for each fold: [4.184239448062009, 4.18787572994602, 4.189215691250026, 4.18746782939986, 4.184149922642626]\n",
      "Mean RMSE: 4.186589724260108\n",
      "\n",
      "Best RMSE: 4.18140459771053\n",
      "Best params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008065429868602329, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.007419939418114052, 'pca__n_components': 20}\n",
      "Best RMSE: 4.18140459771053\n",
      "Best params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008065429868602329, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.007419939418114052, 'pca__n_components': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import uniform\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "num_cols = features.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"mlp\", MLPRegressor(max_iter=200, early_stopping=True, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"pca__n_components\": [20, 30],\n",
    "    \"mlp__hidden_layer_sizes\": [(32,), (64,), (64,32)],\n",
    "    \"mlp__activation\": [\"relu\", \"tanh\"],\n",
    "    \"mlp__alpha\": uniform(loc=1e-5, scale=1e-3),\n",
    "    \"mlp__learning_rate_init\": uniform(loc=1e-4, scale=1e-2)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, yields, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "for i, params in enumerate(search.cv_results_['params']):\n",
    "    fold_scores = search.cv_results_['split0_test_score'][i], search.cv_results_['split1_test_score'][i], \\\n",
    "                  search.cv_results_['split2_test_score'][i], search.cv_results_['split3_test_score'][i], \\\n",
    "                  search.cv_results_['split4_test_score'][i]\n",
    "    fold_scores = [-s for s in fold_scores]  # convert to positive RMSE\n",
    "    print(f\"Params: {params}\")\n",
    "    print(f\"RMSE for each fold: {fold_scores}\")\n",
    "    print(f\"Mean RMSE: {np.mean(fold_scores)}\\n\")\n",
    "\n",
    "print(\"Best RMSE:\", -search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "print(\"Best RMSE:\", -search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02a42368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.191633002956586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['no_farm_mlp_cattle_model.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "best_params = search.best_params_\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=best_params[\"pca__n_components\"])),\n",
    "    (\"mlp\", MLPRegressor(\n",
    "        hidden_layer_sizes=best_params[\"mlp__hidden_layer_sizes\"],\n",
    "        activation=best_params[\"mlp__activation\"],\n",
    "        alpha=best_params[\"mlp__alpha\"],\n",
    "        learning_rate_init=best_params[\"mlp__learning_rate_init\"],\n",
    "        early_stopping=True,\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_pipe.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "joblib.dump(final_pipe, \"no_farm_mlp_cattle_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bccc4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mlp_cattle_model_final2.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "num_cols = features.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "best_params = search.best_params_\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=best_params[\"pca__n_components\"])),\n",
    "    (\"mlp\", MLPRegressor(\n",
    "        hidden_layer_sizes=best_params[\"mlp__hidden_layer_sizes\"],\n",
    "        activation=best_params[\"mlp__activation\"],\n",
    "        alpha=best_params[\"mlp__alpha\"],\n",
    "        learning_rate_init=best_params[\"mlp__learning_rate_init\"],\n",
    "        early_stopping=True,\n",
    "        max_iter=200,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(features, yields)\n",
    "\n",
    "joblib.dump(pipe, \"mlp_cattle_model_final2.pkl\")\n",
    "print(\"Saved mlp_cattle_model_final2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9776b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 14)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"cattle_data_test.csv\")\n",
    "test_data_cleaned = test_data.drop(columns=features_to_remove)\n",
    "\n",
    "test_data_cleaned['Date'] = pd.to_datetime(test_data_cleaned['Date'])\n",
    "test_data_cleaned['Month'] = test_data_cleaned['Date'].dt.month\n",
    "test_data_cleaned['Season'] = test_data_cleaned['Month'].apply(get_season)\n",
    "test_data_cleaned = test_data_cleaned.drop(columns=['Date', 'Month'])\n",
    "\n",
    "test_features = test_data_cleaned\n",
    "\n",
    "print(test_features.shape)\n",
    "# test_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac717076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to milk_yield_predictions4.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "pipeline = joblib.load(\"mlp_cattle_model_final2.pkl\")\n",
    "\n",
    "predictions = pipeline.predict(test_features)\n",
    "\n",
    "output = pd.DataFrame({\n",
    "    \"Cattle_ID\": test_data[\"Cattle_ID\"],\n",
    "    \"Milk_Yield_L\": predictions\n",
    "})\n",
    "\n",
    "output.to_csv(\"milk_yield_predictions4.csv\", index=False)\n",
    "print(\"Predictions saved to milk_yield_predictions4.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
