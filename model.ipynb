{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9c0ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87ea42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cattle_data_train.csv\")\n",
    "\n",
    "features = data.iloc[:, 1:-1]\n",
    "yields = data.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c03tkdlkdj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (210000, 36)\n",
      "Cleaned shape: (210000, 24)\n",
      "Removed 12 features\n"
     ]
    }
   ],
   "source": [
    "# Feature Removal and Preprocessing\n",
    "# Based on correlation analysis and data quality issues\n",
    "\n",
    "# Features to remove:\n",
    "features_to_remove = [\n",
    "    'Feed_Quantity_lb',      # Duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "    'Cattle_ID',             # Unique identifier, no predictive value\n",
    "    'Rumination_Time_hrs',   # 55% negative values - data quality issue\n",
    "    'HS_Vaccine',            # Very low correlation (0.000034)\n",
    "    'BQ_Vaccine',            # Very low correlation (0.000466)\n",
    "    'BVD_Vaccine',           # Very low correlation (0.000491)\n",
    "    'Brucellosis_Vaccine',   # Very low correlation (0.002089)\n",
    "    'FMD_Vaccine',           # Very low correlation (0.002477)\n",
    "    'Anthrax_Vaccine', \n",
    "    'IBR_Vaccine', \n",
    "    'Rabies_Vaccine',\n",
    "    # 'Resting_Hours',         # Nearly zero correlation (0.001653)\n",
    "    'Housing_Score',         # Low correlation (0.004) + 3% missing values\n",
    "    # 'Feeding_Frequency',     # No correlation (0.000380)\n",
    "    # 'Walking_Distance_km',   # No correlation (0.001538)\n",
    "    # 'Body_Condition_Score',  # No correlation (0.001647)\n",
    "    # 'Humidity_percent',      # Very low correlation (0.002153)\n",
    "    # 'Grazing_Duration_hrs',  # Very low correlation (0.004350)\n",
    "    # 'Milking_Interval_hrs'   # Very low correlation (0.014734)\n",
    "]\n",
    "\n",
    "# Remove features\n",
    "data_cleaned = data.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"Cleaned shape: {data_cleaned.shape}\")\n",
    "print(f\"Removed {len(features_to_remove)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "qb4zf4aahh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced Date with Season:\n",
      "  - Season (Winter/Spring/Summer/Fall)\n",
      "\n",
      "Season distribution:\n",
      "Season\n",
      "Fall      52425\n",
      "Spring    53061\n",
      "Summer    52663\n",
      "Winter    51851\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final shape: (210000, 24)\n"
     ]
    }
   ],
   "source": [
    "# Extract Season from Date column\n",
    "# Analysis shows seasons have strong effect on milk yield:\n",
    "#   - Spring: 16.59 L (+6.4% vs average) - BEST season\n",
    "#   - Winter: 16.12 L (+3.4% vs average)\n",
    "#   - Fall:   15.70 L (+0.7% vs average)\n",
    "#   - Summer: 13.94 L (-10.6% vs average) - WORST season (heat stress)\n",
    "#   - Range: 2.65 L difference between best and worst seasons!\n",
    "\n",
    "# Convert Date to datetime\n",
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "\n",
    "# Extract month temporarily to create seasons\n",
    "data_cleaned['Month'] = data_cleaned['Date'].dt.month\n",
    "\n",
    "# Create Season feature (meteorological seasons)\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Fall'\n",
    "\n",
    "data_cleaned['Season'] = data_cleaned['Month'].apply(get_season)\n",
    "\n",
    "# Drop both Date and Month (we only keep Season)\n",
    "data_cleaned = data_cleaned.drop(columns=['Date', 'Month'])\n",
    "\n",
    "print(\"Replaced Date with Season:\")\n",
    "print(\"  - Season (Winter/Spring/Summer/Fall)\")\n",
    "print(f\"\\nSeason distribution:\")\n",
    "print(data_cleaned['Season'].value_counts().sort_index())\n",
    "print(f\"\\nFinal shape: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ced80a13fbi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (210000, 23)\n",
      "Target shape: (210000,)\n"
     ]
    }
   ],
   "source": [
    "# Update features and target using cleaned data\n",
    "features = data_cleaned.drop(columns=['Milk_Yield_L'])\n",
    "yields = data_cleaned['Milk_Yield_L']\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target shape: {yields.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rxi9fuc5r6j",
   "metadata": {},
   "source": [
    "## Summary of Feature Selection\n",
    "\n",
    "**Removed 16 features:**\n",
    "1. Feed_Quantity_lb - duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "2. Cattle_ID - unique identifier, no predictive value\n",
    "3. Rumination_Time_hrs - data quality issue (55% negative values)\n",
    "4-8. Low-correlation vaccines: HS, BQ, BVD, Brucellosis, FMD\n",
    "9-15. Zero/near-zero correlation: Resting_Hours, Housing_Score, Feeding_Frequency, Walking_Distance_km, Body_Condition_Score, Humidity_percent, Grazing_Duration_hrs\n",
    "16. Milking_Interval_hrs - very low correlation (0.015)\n",
    "\n",
    "**Replaced Date with Season:**\n",
    "- Removed: Date (raw timestamp)\n",
    "- Added: Season (Winter/Spring/Summer/Fall)\n",
    "- Rationale: Strong seasonal effect on milk yield (Spring: 16.59L vs Summer: 13.94L = 2.65L range)\n",
    "- Month was NOT kept (redundant with Season - only 0.1L variation within seasons)\n",
    "\n",
    "**Final: 19 features (down from 35 = 46% reduction)**\n",
    "\n",
    "**Categorical (7):**\n",
    "- Breed, Climate_Zone, Management_System, Lactation_Stage, Feed_Type, Farm_ID, Season\n",
    "\n",
    "**Numeric (12):**\n",
    "- Age_Months (corr: 0.31), Weight_kg (0.30), Parity (0.24), Days_in_Milk (0.06), Feed_Quantity_kg (0.22), Water_Intake_L (0.12), Ambient_Temperature_C (0.04), Anthrax_Vaccine (0.07), IBR_Vaccine (0.07), Rabies_Vaccine (0.07), Previous_Week_Avg_Yield (0.09), Mastitis (0.12)\n",
    "\n",
    "**Why this works:**\n",
    "- Removed noisy, low-correlation features\n",
    "- Kept strong predictors (Age, Weight, Parity, Feed)\n",
    "- Captured seasonal patterns without overfitting to specific months\n",
    "- Cleaner data (fixed Rumination_Time_hrs corruption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a304fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Breed', 'Climate_Zone', 'Management_System', 'Lactation_Stage', 'Feed_Type', 'Farm_ID', 'Season']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Update categorical columns from cleaned data\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "print(f\"Categorical columns: {cat_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4738e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, mode=\"freq\", m=5):\n",
    "        self.cols = cols\n",
    "        self.mode = mode\n",
    "        self.m = m\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.maps = {}\n",
    "\n",
    "        for col in self.cols:\n",
    "            freq = X[col].value_counts()\n",
    "            total = len(X)\n",
    "\n",
    "            if self.mode == \"freq\":\n",
    "                enc = freq / total\n",
    "            elif self.mode == \"count\":\n",
    "                enc = freq\n",
    "            elif self.mode == \"logfreq\":\n",
    "                enc = np.log1p(freq / total)\n",
    "            elif self.mode == \"smooth\":\n",
    "                prior = freq.sum() / total\n",
    "                enc = (freq + self.m * prior) / (freq.sum() + self.m)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown mode: \" + self.mode)\n",
    "\n",
    "            self.maps[col] = enc\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].map(self.maps[col]).fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57dcca38",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m X_test_scaled = scaler.transform(X_test)\n\u001b[32m     53\u001b[39m pca = PCA(n_components=\u001b[32m50\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m X_train_pca = \u001b[43mpca\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m X_test_pca = pca.transform(X_test_scaled)\n\u001b[32m     57\u001b[39m model = MLPRegressor(**best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\decomposition\\_pca.py:466\u001b[39m, in \u001b[36mPCA.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    445\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m \u001b[33;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     U, S, _, X, x_is_centered, xp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m U \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         U = U[:, : \u001b[38;5;28mself\u001b[39m.n_components_]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\decomposition\\_pca.py:542\u001b[39m, in \u001b[36mPCA._fit\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_full(X, n_components, xp, is_array_api_compliant)\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33marpack\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrandomized\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m542\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_truncated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\decomposition\\_pca.py:757\u001b[39m, in \u001b[36mPCA._fit_truncated\u001b[39m\u001b[34m(self, X, n_components, xp)\u001b[39m\n\u001b[32m    753\u001b[39m     U, Vt = svd_flip(U[:, ::-\u001b[32m1\u001b[39m], Vt[::-\u001b[32m1\u001b[39m], u_based_decision=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m svd_solver == \u001b[33m\"\u001b[39m\u001b[33mrandomized\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# sign flipping is done inside\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     U, S, Vt = \u001b[43m_randomized_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_centered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_oversamples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_oversamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterated_power\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflip_sign\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    765\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m     U, Vt = svd_flip(U, Vt, u_based_decision=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    768\u001b[39m \u001b[38;5;28mself\u001b[39m.n_samples_ = n_samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:568\u001b[39m, in \u001b[36m_randomized_svd\u001b[39m\u001b[34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[32m    565\u001b[39m     \u001b[38;5;66;03m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[32m    566\u001b[39m     M = M.T\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m Q = \u001b[43m_randomized_range_finder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_random\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[32m    577\u001b[39m B = Q.T @ M\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:351\u001b[39m, in \u001b[36m_randomized_range_finder\u001b[39m\u001b[34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[32m    350\u001b[39m     Q, _ = normalizer(A @ Q)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     Q, _ = \u001b[43mnormalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# Sample the range of A using by linear projection of Q\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[38;5;66;03m# Extract an orthonormal basis\u001b[39;00m\n\u001b[32m    355\u001b[39m Q, _ = qr_normalizer(A @ Q)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\linalg\\_decomp_lu.py:186\u001b[39m, in \u001b[36mlu\u001b[39m\u001b[34m(a, permute_l, overwrite_a, check_finite, p_indices)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33mth argument of internal gesv|posv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    183\u001b[39m                      % -info)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlu\u001b[39m(a, permute_l=\u001b[38;5;28;01mFalse\u001b[39;00m, overwrite_a=\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    187\u001b[39m        p_indices=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    188\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03m    Compute LU decomposition of a matrix with partial pivoting.\u001b[39;00m\n\u001b[32m    190\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    280\u001b[39m \n\u001b[32m    281\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    282\u001b[39m     a1 = np.asarray_chkfinite(a) \u001b[38;5;28;01mif\u001b[39;00m check_finite \u001b[38;5;28;01melse\u001b[39;00m np.asarray(a)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "best_params = {\n",
    "    \"activation\": \"relu\",\n",
    "    \"alpha\": 0.000606850157946487,\n",
    "    \"hidden_layer_sizes\": (64,),\n",
    "    \"learning_rate_init\": 0.0016599452033620266,\n",
    "    \"max_iter\": 200,\n",
    "    \"early_stopping\": True,\n",
    "    \"tol\": 1e-3,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    df_filled = df.copy()\n",
    "    for col in df_filled.columns:\n",
    "        if df_filled[col].dtype in [\"float64\", \"int64\"]:\n",
    "            df_filled[col] = df_filled[col].fillna(df_filled[col].median())\n",
    "        else:\n",
    "            df_filled[col] = df_filled[col].fillna(df_filled[col].mode()[0])\n",
    "    return df_filled\n",
    "\n",
    "def one_hot_encode(X, cat_cols):\n",
    "    X = pd.get_dummies(X, columns=cat_cols, drop_first=False)\n",
    "    return X\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_rmse = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(features):\n",
    "    X_train, X_test = features.iloc[train_idx], features.iloc[test_idx]\n",
    "    y_train, y_test = yields.iloc[train_idx], yields.iloc[test_idx]\n",
    "\n",
    "    X_train = fill_missing_values(X_train)\n",
    "    X_test = fill_missing_values(X_test)\n",
    "\n",
    "    X_train = one_hot_encode(X_train, cat_cols)\n",
    "    X_test = one_hot_encode(X_test, cat_cols)\n",
    "\n",
    "    # Align columns to avoid mismatch after one-hot encoding\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    pca = PCA(n_components=50)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    model = MLPRegressor(**best_params)\n",
    "    model.fit(X_train_pca, y_train)\n",
    "\n",
    "    pred = model.predict(X_test_pca)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_test, pred))\n",
    "    fold_rmse.append(rmse_val)\n",
    "    print(\"RMSE:\", rmse_val)\n",
    "\n",
    "print(\"Average RMSE:\", np.mean(fold_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f539e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008065429868602329, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.007419939418114052, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.190529002246665, 4.246414638325021, 4.215144693983486, 4.224961829741235, 4.218819999768525]\n",
      "Mean RMSE: 4.219174032812986\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.00016601864044243653, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0010997491581800289, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.224449816827385, 4.226797262040572, 4.21526284334641, 4.228052518081616, 4.2021632945820855]\n",
      "Mean RMSE: 4.219345146975614\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.00034370861113902185, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0003058449429580245, 'pca__n_components': 150}\n",
      "RMSE for each fold: [4.215871631481402, 4.240875152731056, 4.184725316331051, 4.2242673257333765, 4.2093591385521725]\n",
      "Mean RMSE: 4.215019712965812\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0008424426408004218, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00010778765841014329, 'pca__n_components': 150}\n",
      "RMSE for each fold: [4.2367213164124795, 4.25852076511799, 4.251218665328553, 4.258511261984614, 4.23365140260098]\n",
      "Mean RMSE: 4.247724682288924\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0006274815096277166, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.005347564316322379, 'pca__n_components': 150}\n",
      "RMSE for each fold: [4.23788656626042, 4.26208732281395, 4.243717826352284, 4.256485067479363, 4.220362971672307]\n",
      "Mean RMSE: 4.244107950915665\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.00030122914019804195, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.004098609717152555, 'pca__n_components': 150}\n",
      "RMSE for each fold: [4.2325089160454565, 4.259069119359608, 4.234558237614477, 4.259168283530856, 4.219821626587128]\n",
      "Mean RMSE: 4.241025236627505\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009837555188414592, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.004660699842170359, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.197402315986853, 4.213717658005472, 4.1964369615298525, 4.223158841045309, 4.180644381973683]\n",
      "Mean RMSE: 4.202272031708233\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.00020967378215835974, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.009932308858067881, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.211094514873222, 4.2165845198472, 4.20975674000939, 4.225458731051939, 4.190420737231529]\n",
      "Mean RMSE: 4.210663048602656\n",
      "\n",
      "Params: {'mlp__activation': 'relu', 'mlp__alpha': 0.0008699404067363205, 'mlp__hidden_layer_sizes': (64, 32), 'mlp__learning_rate_init': 0.0018052412368729153, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.22724327065667, 4.224275446806125, 4.21337629000702, 4.246617990763111, 4.206021696618022]\n",
      "Mean RMSE: 4.223506938970191\n",
      "\n",
      "Params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009588855372533333, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00818397348116461, 'pca__n_components': 50}\n",
      "RMSE for each fold: [4.195073920617332, 4.208200154774792, 4.201727197646048, 4.2206457302232145, 4.1795053098420984]\n",
      "Mean RMSE: 4.201030462620698\n",
      "\n",
      "Best RMSE: 4.201030462620698\n",
      "Best params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009588855372533333, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00818397348116461, 'pca__n_components': 50}\n",
      "Best RMSE: 4.201030462620698\n",
      "Best params: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0009588855372533333, 'mlp__hidden_layer_sizes': (64,), 'mlp__learning_rate_init': 0.00818397348116461, 'pca__n_components': 50}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import uniform\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "num_cols = features.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"mlp\", MLPRegressor(max_iter=200, early_stopping=True, tol=1e-3, random_state=42))\n",
    "])\n",
    "\n",
    "param_distributions = {\n",
    "    \"pca__n_components\": [50, 150],\n",
    "    \"mlp__hidden_layer_sizes\": [(32,), (64,), (64,32)],\n",
    "    \"mlp__activation\": [\"relu\", \"tanh\"],\n",
    "    \"mlp__alpha\": uniform(loc=1e-5, scale=1e-3),\n",
    "    \"mlp__learning_rate_init\": uniform(loc=1e-4, scale=1e-2)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(features, yields)\n",
    "\n",
    "for i, params in enumerate(search.cv_results_['params']):\n",
    "    fold_scores = search.cv_results_['split0_test_score'][i], search.cv_results_['split1_test_score'][i], \\\n",
    "                  search.cv_results_['split2_test_score'][i], search.cv_results_['split3_test_score'][i], \\\n",
    "                  search.cv_results_['split4_test_score'][i]\n",
    "    fold_scores = [-s for s in fold_scores]  # convert to positive RMSE\n",
    "    print(f\"Params: {params}\")\n",
    "    print(f\"RMSE for each fold: {fold_scores}\")\n",
    "    print(f\"Mean RMSE: {np.mean(fold_scores)}\\n\")\n",
    "\n",
    "print(\"Best RMSE:\", -search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "print(\"Best RMSE:\", -search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bccc4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved as mlp_cattle_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "num_cols = features.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "best_params = {\n",
    "    \"mlp__activation\": \"tanh\",\n",
    "    \"mlp__alpha\": 0.0009588855372533333,\n",
    "    \"mlp__hidden_layer_sizes\": (64,),\n",
    "    \"mlp__learning_rate_init\": 0.00818397348116461,\n",
    "    \"pca__n_components\": 50,\n",
    "    \"mlp__max_iter\": 200,\n",
    "    \"mlp__early_stopping\": True,\n",
    "    \"mlp__tol\": 1e-3,\n",
    "    \"mlp__random_state\": 42\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=best_params.pop(\"pca__n_components\"))),\n",
    "    (\"mlp\", MLPRegressor(**{k.replace(\"mlp__\", \"\"): v for k, v in best_params.items()}))\n",
    "])\n",
    "\n",
    "pipe.fit(features, yields)\n",
    "\n",
    "joblib.dump(pipe, \"mlp_cattle_model.pkl\")\n",
    "print(\"Model trained and saved as mlp_cattle_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
