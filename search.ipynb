{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9c0ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ea42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cattle_data_train.csv\")\n",
    "\n",
    "features = data.iloc[:, 1:-1]\n",
    "yields = data.iloc[:, -1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c03tkdlkdj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (210000, 36)\n",
      "Cleaned shape: (210000, 27)\n",
      "Removed 9 features\n"
     ]
    }
   ],
   "source": [
    "# Feature Removal and Preprocessing\n",
    "# Based on correlation analysis and data quality issues\n",
    "\n",
    "# Features to remove (15 total):\n",
    "features_to_remove = [\n",
    "    'Feed_Quantity_lb',      # Duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "    'Cattle_ID',             # Unique identifier, no predictive value\n",
    "    'Rumination_Time_hrs',   # 55% negative values - data quality issue\n",
    "    'HS_Vaccine',            # Very low correlation (0.000034)\n",
    "    'BQ_Vaccine',            # Very low correlation (0.000466)\n",
    "    'BVD_Vaccine',           # Very low correlation (0.000491)\n",
    "    'Brucellosis_Vaccine',   # Very low correlation (0.002089)\n",
    "    'FMD_Vaccine',           # Very low correlation (0.002477)\n",
    "    # 'Resting_Hours',         # Nearly zero correlation (0.001653)\n",
    "    'Housing_Score',         # Low correlation (0.004) + 3% missing values\n",
    "    # 'Previous_Week_Avg_Yield',  # Similarity to another col\n",
    "    # 'Feeding_Frequency',     # No correlation (0.000380)\n",
    "    # 'Walking_Distance_km',   # No correlation (0.001538)\n",
    "    # 'Body_Condition_Score',  # No correlation (0.001647)\n",
    "    # 'Humidity_percent',      # Very low correlation (0.002153)\n",
    "    # 'Grazing_Duration_hrs',  # Very low correlation (0.004350)\n",
    "    # 'Milking_Interval_hrs'   # Very low correlation (0.014734)\n",
    "]\n",
    "\n",
    "# Remove features\n",
    "data_cleaned = data.drop(columns=features_to_remove)\n",
    "\n",
    "print(f\"Original shape: {data.shape}\")\n",
    "print(f\"Cleaned shape: {data_cleaned.shape}\")\n",
    "print(f\"Removed {len(features_to_remove)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "qb4zf4aahh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced Date with Season:\n",
      "  - Season (Winter/Spring/Summer/Fall)\n",
      "\n",
      "Season distribution:\n",
      "Season\n",
      "Fall      52425\n",
      "Spring    53061\n",
      "Summer    52663\n",
      "Winter    51851\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final shape: (210000, 27)\n"
     ]
    }
   ],
   "source": [
    "# Extract Season from Date column\n",
    "# Analysis shows seasons have strong effect on milk yield:\n",
    "#   - Spring: 16.59 L (+6.4% vs average) - BEST season\n",
    "#   - Winter: 16.12 L (+3.4% vs average)\n",
    "#   - Fall:   15.70 L (+0.7% vs average)\n",
    "#   - Summer: 13.94 L (-10.6% vs average) - WORST season (heat stress)\n",
    "#   - Range: 2.65 L difference between best and worst seasons!\n",
    "\n",
    "# Convert Date to datetime\n",
    "data_cleaned['Date'] = pd.to_datetime(data_cleaned['Date'])\n",
    "\n",
    "# Extract month temporarily to create seasons\n",
    "data_cleaned['Month'] = data_cleaned['Date'].dt.month\n",
    "\n",
    "# Create Season feature (meteorological seasons)\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:  # 9, 10, 11\n",
    "        return 'Fall'\n",
    "\n",
    "data_cleaned['Season'] = data_cleaned['Month'].apply(get_season)\n",
    "\n",
    "# Drop both Date and Month (we only keep Season)\n",
    "data_cleaned = data_cleaned.drop(columns=['Date', 'Month'])\n",
    "\n",
    "print(\"Replaced Date with Season:\")\n",
    "print(\"  - Season (Winter/Spring/Summer/Fall)\")\n",
    "print(f\"\\nSeason distribution:\")\n",
    "print(data_cleaned['Season'].value_counts().sort_index())\n",
    "print(f\"\\nFinal shape: {data_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ced80a13fbi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (210000, 26)\n",
      "Target shape: (210000,)\n"
     ]
    }
   ],
   "source": [
    "# Update features and target using cleaned data\n",
    "features = data_cleaned.drop(columns=['Milk_Yield_L'])\n",
    "yields = data_cleaned['Milk_Yield_L']\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target shape: {yields.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rxi9fuc5r6j",
   "metadata": {},
   "source": [
    "## Summary of Feature Selection\n",
    "\n",
    "**Removed 16 features:**\n",
    "1. Feed_Quantity_lb - duplicate of Feed_Quantity_kg (99.99% correlation)\n",
    "2. Cattle_ID - unique identifier, no predictive value\n",
    "3. Rumination_Time_hrs - data quality issue (55% negative values)\n",
    "4-8. Low-correlation vaccines: HS, BQ, BVD, Brucellosis, FMD\n",
    "9-15. Zero/near-zero correlation: Resting_Hours, Housing_Score, Feeding_Frequency, Walking_Distance_km, Body_Condition_Score, Humidity_percent, Grazing_Duration_hrs\n",
    "16. Milking_Interval_hrs - very low correlation (0.015)\n",
    "\n",
    "**Replaced Date with Season:**\n",
    "- Removed: Date (raw timestamp)\n",
    "- Added: Season (Winter/Spring/Summer/Fall)\n",
    "- Rationale: Strong seasonal effect on milk yield (Spring: 16.59L vs Summer: 13.94L = 2.65L range)\n",
    "- Month was NOT kept (redundant with Season - only 0.1L variation within seasons)\n",
    "\n",
    "**Final: 19 features (down from 35 = 46% reduction)**\n",
    "\n",
    "**Categorical (7):**\n",
    "- Breed, Climate_Zone, Management_System, Lactation_Stage, Feed_Type, Farm_ID, Season\n",
    "\n",
    "**Numeric (12):**\n",
    "- Age_Months (corr: 0.31), Weight_kg (0.30), Parity (0.24), Days_in_Milk (0.06), Feed_Quantity_kg (0.22), Water_Intake_L (0.12), Ambient_Temperature_C (0.04), Anthrax_Vaccine (0.07), IBR_Vaccine (0.07), Rabies_Vaccine (0.07), Previous_Week_Avg_Yield (0.09), Mastitis (0.12)\n",
    "\n",
    "**Why this works:**\n",
    "- Removed noisy, low-correlation features\n",
    "- Kept strong predictors (Age, Weight, Parity, Feed)\n",
    "- Captured seasonal patterns without overfitting to specific months\n",
    "- Cleaner data (fixed Rumination_Time_hrs corruption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a304fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Breed', 'Climate_Zone', 'Management_System', 'Lactation_Stage', 'Feed_Type', 'Farm_ID', 'Season']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Update categorical columns from cleaned data\n",
    "cat_cols = features.select_dtypes(include=[\"object\", \"string\"]).columns.tolist()\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "num_cols = [c for c in features.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4738e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, mode=\"freq\", m=5):\n",
    "        self.cols = cols\n",
    "        self.mode = mode\n",
    "        self.m = m\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.maps = {}\n",
    "\n",
    "        for col in self.cols:\n",
    "            freq = X[col].value_counts()\n",
    "            total = len(X)\n",
    "\n",
    "            if self.mode == \"freq\":\n",
    "                enc = freq / total\n",
    "            elif self.mode == \"count\":\n",
    "                enc = freq\n",
    "            elif self.mode == \"logfreq\":\n",
    "                enc = np.log1p(freq / total)\n",
    "            elif self.mode == \"smooth\":\n",
    "                prior = freq.sum() / total\n",
    "                enc = (freq + self.m * prior) / (freq.sum() + self.m)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown mode: \" + self.mode)\n",
    "\n",
    "            self.maps[col] = enc\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in self.cols:\n",
    "            X[col] = X[col].map(self.maps[col]).fillna(0)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57dcca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 1052)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def fill_missing_values(df):\n",
    "    df_filled = df.copy()\n",
    "\n",
    "    for col in df_filled.columns:\n",
    "        if df_filled[col].dtype in [\"float64\", \"int64\"]:\n",
    "            df_filled[col] = df_filled[col].fillna(df_filled[col].median())\n",
    "        else:  \n",
    "            df_filled[col] = df_filled[col].fillna(df_filled[col].mode()[0])\n",
    "    \n",
    "    return df_filled\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import pandas as pd\n",
    "\n",
    "def fill_with_similar_fast(df):\n",
    "    imputer = IterativeImputer(\n",
    "        random_state=42,\n",
    "        max_iter=10,\n",
    "        initial_strategy=\"most_frequent\"\n",
    "    )\n",
    "    arr = imputer.fit_transform(df)\n",
    "    return pd.DataFrame(arr, columns=df.columns)\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(X, cat_cols):\n",
    "    X = X.copy()\n",
    "    X = pd.get_dummies(X, columns=cat_cols, drop_first=False)\n",
    "    return X\n",
    "\n",
    "features = fill_missing_values(features)\n",
    "features = one_hot_encode(features, cat_cols)\n",
    "print(features.shape)\n",
    "# features = fill_with_similar_fast(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.203492862909782\n",
      "RMSE: 4.142938294772711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from scipy.stats import uniform\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def make_pipeline(use_pca=True, n_components=None):\n",
    "    steps = [(\"scaler\", StandardScaler())]\n",
    "    if use_pca:\n",
    "        steps.append((\"pca\", PCA(n_components=n_components)))\n",
    "    steps.append((\"mlp\", MLPRegressor(max_iter=200, early_stopping=True, tol=1e-3, random_state=42)))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "param_space = {\n",
    "    \"pca__n_components\": [50, 150, 300],\n",
    "    \"mlp__hidden_layer_sizes\": [(32,), (64,), (64,32)],\n",
    "    \"mlp__activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "    \"mlp__alpha\": uniform(loc=1e-5, scale=1e-3),\n",
    "    \"mlp__learning_rate_init\": uniform(loc=1e-4, scale=1e-2)\n",
    "}\n",
    "\n",
    "pipe = make_pipeline(use_pca=True)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_space,\n",
    "    n_iter=20,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(features, yields)\n",
    "\n",
    "print(\"Best RMSE:\", -search.best_score_)\n",
    "print(\"Best params:\", search.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
